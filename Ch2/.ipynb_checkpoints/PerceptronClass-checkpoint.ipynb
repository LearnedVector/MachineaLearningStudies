{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron class in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eta: float\n",
    "        Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "        Passes over the training dataset.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    w_ : 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_: list\n",
    "        Number of misclassifications in every epoch.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the \n",
    "            number of samples and n_features is the \n",
    "            number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input or (w^t)x\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unity step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation for net_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The self.w_[0] is basically the \"threshold\" or so-called \"bias unit.\" I simply included the bias unit in the weight vector, which makes the math part easier, but on the other hand, it may make the code more confusing as you mentioned.\n",
    "\n",
    "Let's say we have a 3x2 dimensional dataset X (3 training samples with 2 features). Also, let's just assume we have a weight 2 for feature 1 and a weight 3 for feature 2, and we set the bias unit to 4. This is how you would normally do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =\n",
      " [[ 2.  3.]\n",
      " [ 4.  5.]\n",
      " [ 6.  7.]]\n",
      "w =\n",
      " [ 4.  2.  3.]\n"
     ]
    }
   ],
   "source": [
    "bias = 4\n",
    "X = np.array([[2.,3.], [4.,5.], [6.,7.]])\n",
    "w = np.array([bias, 2., 3.])\n",
    "print(\"X =\\n\",X)\n",
    "print(\"w =\\n\",w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to match the mathematical notation, we would have to add a vector of 1s to compute the dot-product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector of ones = \n",
      " [[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "X with 1 = \n",
      " [[ 1.  2.  3.]\n",
      " [ 1.  4.  5.]\n",
      " [ 1.  6.  7.]]\n",
      "value from dot product = \n",
      " [ 17.  27.  37.]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((X.shape[0], 1))\n",
    "print(\"vector of ones = \\n\",ones)\n",
    "\n",
    "X_with1 = np.hstack((ones, X))\n",
    "print(\"X with 1 = \\n\", X_with1)\n",
    "dotProd = np.dot(X_with1, w)\n",
    "\n",
    "print(\"value from dot product = \\n\", dotProd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, I thought that adding a vector of 1s to the training array each time we want to make a prediction would be fairly inefficient. So, instead, we can just \"add\" the bias unit (w[0]) to the do product (it's equivalent, since 1.0 * w_0 = w_0:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17.  27.  37.]\n"
     ]
    }
   ],
   "source": [
    "efficient = np.dot(X, w[1:]) + w[0]\n",
    "print(efficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matrix operation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "| 1  2  3 |   | 4 |   | 1*4 + 2*2 + 3*3 |   | 17 |\n",
    "| 1  4  5 | x | 2 | = | 1*4 + 4*2 + 5*3 | = | 27 |\n",
    "| 1  6  7 |   | 3 |   | 1*4 + 6*2 + 7*3 |   | 37 |\n",
    "\n",
    "which is the same as...\n",
    "\n",
    "| 2  3 |   | 4 |          | 2*2 + 3*3 |          | 13 + bias |   | 17 |\n",
    "| 4  5 | x | 2 | + bias = | 4*2 + 5*3 | + bias = | 23 + bias | = | 27 |\n",
    "| 6  7 |   | 3 |          | 6*2 + 7*3 |          | 33 + bias |   | 37 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
